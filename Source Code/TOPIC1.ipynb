{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of YOLO.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_alhvVEGy3D1",
        "colab_type": "text"
      },
      "source": [
        "Xây dựng bộ phát hiện đối tượng với thuật toán YOLOv3 được viết bằng thư viện Keras. Thư viện này bao gồm đầy đủ các module: phát hiện đối tượng với pre-trainded model, huấn luyện lại mô hình, phát hiện đối tượng ảnh trên ảnh/video/webcam.\n",
        "\n",
        "Đầu tiên, ta sẽ khởi tạo Google Colab với sử dụng 1 GPU. Sau đó thực hiện kết nối với Google Drive của tài khoản cá nhân như sau:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWYdIEs4GvaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "af0d7e3a-9d96-4105-ca17-97c7a6783422"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "lab_path = \"/content/gdrive/My\\ Drive/AdvancedComputerVision/keras-yolo3\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey3bs8vR3NPn",
        "colab_type": "text"
      },
      "source": [
        "Sau đó, sử dụng git để clone thư mục project từ github của tác giả experiencor với đường dẫn như sau. Lưu ý rằng, ta nên đặt thực project kế bên file jupyter notebook này để tiện thao tác."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_PW5hu4IdXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!git clone https://github.com/experiencor/keras-yolo3.git $lab_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ppso2Gj3vnV",
        "colab_type": "text"
      },
      "source": [
        "Sau đó tiến hành cài đặt các thư viện cần thiết để có thể sử dụng được keras-yolo3. Đây là bước thực hiện quan trọng vì thông thường các thư viện sẽ sử dụng các thư viện bên thứ 3 với các phiên bản cố định. Do đó, để đảm bảo thư viện keras-yolo3 sử dụng trơn tru thì ta sẽ cài đặt các thư viện kèm theo trong file requirements.txt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjQWjajkJBSX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4998b1a8-3eee-40c1-82da-0ec38d14a5d7"
      },
      "source": [
        "!pip install -r $lab_path/requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: absl-py==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 2)) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting google-pasta==0.1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.5MB/s \n",
            "\u001b[?25hCollecting grpcio==1.26.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/8f/f79c5c174bebece41f824dd7b1ba98da45dc2d4c373b38ac6a7f6a5acb5e/grpcio-1.26.0-cp36-cp36m-manylinux2010_x86_64.whl (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 6)) (2.10.0)\n",
            "Requirement already satisfied: Keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 7)) (2.3.1)\n",
            "Requirement already satisfied: Keras-Applications==1.0.8 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 8)) (1.0.8)\n",
            "Collecting Keras-Preprocessing==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.2MB/s \n",
            "\u001b[?25hCollecting Markdown==3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 7.9MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python==4.1.2.30 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 12)) (4.1.2.30)\n",
            "Collecting opt-einsum==3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.5MB/s \n",
            "\u001b[?25hCollecting protobuf==3.11.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ac/838c8c8a5f33a58132dd2ad2a30329f6ae1614a9f56ffb79eaaf71a9d156/protobuf-3.11.2-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 41.7MB/s \n",
            "\u001b[?25hCollecting PyYAML==5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/d9/ea9816aea31beeadccd03f1f8b625ecf8f645bd66744484d162d84803ce5/PyYAML-5.3.tar.gz (268kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 16)) (1.4.1)\n",
            "Collecting six==1.14.0\n",
            "  Downloading https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
            "Collecting tensorboard==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 37.9MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 34kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 31.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 21)) (1.1.0)\n",
            "Requirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.6/dist-packages (from -r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 22)) (4.41.1)\n",
            "Collecting Werkzeug==0.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 39.8MB/s \n",
            "\u001b[?25hCollecting wrapt==1.11.2\n",
            "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
            "Requirement already satisfied: setuptools>=36 in /usr/local/lib/python3.6/dist-packages (from Markdown==3.1.1->-r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 10)) (49.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->-r /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/requirements.txt (line 18)) (0.34.2)\n",
            "Building wheels for collected packages: gast, opt-einsum, PyYAML, wrapt\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=ad613cb165f029f76d7ae84cb4b8d88a1cddb0ca83230b7f69b894ac14887a3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "  Building wheel for opt-einsum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opt-einsum: filename=opt_einsum-3.1.0-cp36-none-any.whl size=61682 sha256=4e33724bf8df70e85b05f338b1deae0aa7f0dc0469e9554c5bda15490c881f19\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3-cp36-cp36m-linux_x86_64.whl size=44229 sha256=08b11e4dd944b2bb1db512220bd0f46b36581e0fea1358df06928d3d76b1c5b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/76/4d/a95b8dd7b452b69e8ed4f68b69e1b55e12c9c9624dd962b191\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.11.2-cp36-cp36m-linux_x86_64.whl size=67534 sha256=a530f84c8e5abfc58780890929748c053a7bdd590a5ecbddbfc3f7ebebc0c4a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
            "Successfully built gast opt-einsum PyYAML wrapt\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, six, google-pasta, grpcio, numpy, Keras-Preprocessing, Markdown, opt-einsum, protobuf, PyYAML, Werkzeug, tensorboard, wrapt, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: google-pasta 0.2.0\n",
            "    Uninstalling google-pasta-0.2.0:\n",
            "      Successfully uninstalled google-pasta-0.2.0\n",
            "  Found existing installation: grpcio 1.30.0\n",
            "    Uninstalling grpcio-1.30.0:\n",
            "      Successfully uninstalled grpcio-1.30.0\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "  Found existing installation: Markdown 3.2.2\n",
            "    Uninstalling Markdown-3.2.2:\n",
            "      Successfully uninstalled Markdown-3.2.2\n",
            "  Found existing installation: opt-einsum 3.2.1\n",
            "    Uninstalling opt-einsum-3.2.1:\n",
            "      Successfully uninstalled opt-einsum-3.2.1\n",
            "  Found existing installation: protobuf 3.10.0\n",
            "    Uninstalling protobuf-3.10.0:\n",
            "      Successfully uninstalled protobuf-3.10.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: wrapt 1.12.1\n",
            "    Uninstalling wrapt-1.12.1:\n",
            "      Successfully uninstalled wrapt-1.12.1\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed Keras-Preprocessing-1.1.0 Markdown-3.1.1 PyYAML-5.3 Werkzeug-0.16.0 gast-0.2.2 google-pasta-0.1.8 grpcio-1.26.0 numpy-1.18.1 opt-einsum-3.1.0 protobuf-3.11.2 six-1.14.0 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1 wrapt-1.11.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "grpc",
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3eT3bTp56Hd",
        "colab_type": "text"
      },
      "source": [
        "1. Thử nghiệm với pretrained model của tác giả thuật toán YOLO.\n",
        "\n",
        "File mô hình huấn luyện sẵn được đặt ở đường dẫn sau https://pjreddie.com/media/files/yolov3.weights\n",
        "Lưu ý là file mô hình cần được đặt trong thư mục gốc của thư viện để tiện cho việc thực hiện."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLTQkJH1JR-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget https://pjreddie.com/media/files/yolov3.weights -O $lab_path/yolov3.weights\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDDqM_Xj6Xej",
        "colab_type": "text"
      },
      "source": [
        "Sau đó, ta tiến hành sử dụng pretrained model để phát hiện đối tượng trong ảnh cho trước. Sử dụng chương trình yolo3_one_file_to_detect_them_all.py với file mô hình đã download ở file trước đó để phát hiện các đối tượng trong ảnh. Tập dữ liệu các đối tượng phát hiện được lấy từ tập PASCAL VOC 2012.\n",
        "\n",
        "Ảnh kết quả phát hiện đối tượng trên pretrained model cho tập dữ liệu này được minh hoạ như ở hình sau:\n",
        "\n",
        "![alt text](https://i.imgur.com/6nun5fl.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwIOz_bfJjgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python $lab_path/yolo3_one_file_to_detect_them_all.py -w $lab_path/yolov3.weights -i $lab_path/dog-tales-img.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "190SzOsZ7LUG",
        "colab_type": "text"
      },
      "source": [
        "2. Huấn luyện dữ liệu với keras-yolo3\n",
        "\n",
        "![alt text](https://i.imgur.com/45SRniL.jpg)\n",
        "Bước tiếp theo, ta sẽ tiến hành huấn luyện trên tập dữ liệu mới là gấu mèo (raccoon). Tập dữ liệu này được tải từ https://github.com/experiencor/raccoon_dataset.git\n",
        "\n",
        "Lưu ý rằng, ta sẽ chỉ sử dụng 2 thư mục của github này là images và annotations. Trong đó,\n",
        "\n",
        "*   images: thư mục chứa các ảnh về gấu mèo\n",
        "*   annotations: tương ứng với từng file ảnh của thư mục images, ta có một file .xml chứa thông tin về vị trí chính xác của đối tượng (gấu mèo) trong ảnh.\n",
        "\n",
        "Các bạn nên xem kỹ định dạng của các file XML này để biết cấu trúc file gán nhãn phục vụ cho việc thực hiện đồ án sau này.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuTscS1_eRge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!git clone https://github.com/experiencor/raccoon_dataset.git $lab_path/raccoon_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIgrFV1B_gyo",
        "colab_type": "text"
      },
      "source": [
        "Một file khác cũng rất quan trọng của các mô hình huấn luyện học sâu nói chung và YOLO nói riêng là file cấu hình (config) các tham số khi huấn luyện.\n",
        "\n",
        "Trong thư viện này, file config được đặt trong thư mục /zoo. Ví dụ như config_raccoon.json. Các tham số cơ bản của file config như:\n",
        "- Đường dẫn đến thư mục train, validation (mặc định chia tỉ lệ train:validation = 8:2 nếu không có tham số gắn sẵn)\n",
        "- GPU sử dụng để huấn luyện\n",
        "- File pretrained cho tập image net backend.h5\n",
        "- Learning rate\n",
        "- Batch size\n",
        "\n",
        "Sau khi đã cấu hình file config, ta sẽ tiến hành huấn luyện:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc2dmMk1rjWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3aff9b3-cd2f-4378-a54e-12b27584bcb7"
      },
      "source": [
        "!python $lab_path/train.py -c $lab_path/zoo/config_raccoon.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "2020-07-15 11:52:19.116907: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-07-15 11:52:19.122707: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-07-15 11:52:19.123066: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1590bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-15 11:52:19.123100: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-07-15 11:52:19.124985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-15 11:52:19.233778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 11:52:19.234774: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1590d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-15 11:52:19.234811: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-07-15 11:52:19.234997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 11:52:19.235805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-15 11:52:19.236183: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-15 11:52:19.237406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-15 11:52:19.238572: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-15 11:52:19.238915: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-15 11:52:19.240549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-15 11:52:19.241756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-15 11:52:19.245887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-15 11:52:19.246010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 11:52:19.246937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 11:52:19.247760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-15 11:52:19.247815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-15 11:52:19.249207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-15 11:52:19.249253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-15 11:52:19.249280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-15 11:52:19.249490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 11:52:19.250410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 11:52:19.251294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14652 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/train.py:26: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
            "\n",
            "valid_annot_folder not exists. Spliting the trainining set.\n",
            "Seen labels: \t{'raccoon': 217}\n",
            "\n",
            "Given labels: \t['raccoon']\n",
            "\n",
            "Training on: \t['raccoon']\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/yolo.py:26: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/yolo.py:151: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "resizing:  416 416\n",
            "Epoch 1/103\n",
            "resizing:  448 448\n",
            "2020-07-15 11:53:28.089546: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-15 11:53:32.467924: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/AdvancedComputerVision/keras-yolo3/callbacks.py:19: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "resizing:  448 448\n",
            "resizing:  384 384\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  288 288\n",
            "resizing:  416 416\n",
            "resizing:  448 448\n",
            " - 81s - loss: 404.7240 - yolo_layer_1_loss: 54.1877 - yolo_layer_2_loss: 100.1784 - yolo_layer_3_loss: 250.3579\n",
            "\n",
            "Epoch 00001: loss improved from inf to 404.72396, saving model to /content/raccoon.h5\n",
            "Epoch 2/103\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            "resizing:  352 352\n",
            "resizing:  384 384\n",
            "resizing:  288 288\n",
            "resizing:  448 448\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  384 384\n",
            " - 27s - loss: 69.7715 - yolo_layer_1_loss: 13.5816 - yolo_layer_2_loss: 17.3717 - yolo_layer_3_loss: 38.8182\n",
            "\n",
            "Epoch 00002: loss improved from 404.72396 to 69.77152, saving model to /content/raccoon.h5\n",
            "Epoch 3/103\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  448 448\n",
            "resizing:  384 384\n",
            " - 27s - loss: 43.4903 - yolo_layer_1_loss: 11.4498 - yolo_layer_2_loss: 10.4961 - yolo_layer_3_loss: 21.5444\n",
            "\n",
            "Epoch 00003: loss improved from 69.77152 to 43.49031, saving model to /content/raccoon.h5\n",
            "Epoch 4/103\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  448 448\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            " - 28s - loss: 8.2366 - yolo_layer_1_loss: 5.5225 - yolo_layer_2_loss: 1.1820 - yolo_layer_3_loss: 1.5321\n",
            "\n",
            "Epoch 00004: loss improved from 43.49031 to 8.23662, saving model to /content/raccoon.h5\n",
            "Epoch 5/103\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  384 384\n",
            "resizing:  448 448\n",
            "resizing:  384 384\n",
            "resizing:  384 384\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  384 384\n",
            " - 27s - loss: 4.9340 - yolo_layer_1_loss: 4.0139 - yolo_layer_2_loss: 0.5805 - yolo_layer_3_loss: 0.3396\n",
            "\n",
            "Epoch 00005: loss improved from 8.23662 to 4.93401, saving model to /content/raccoon.h5\n",
            "Epoch 6/103\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            "resizing:  320 320\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            " - 27s - loss: 4.4377 - yolo_layer_1_loss: 3.4478 - yolo_layer_2_loss: 0.7551 - yolo_layer_3_loss: 0.2348\n",
            "\n",
            "Epoch 00006: loss improved from 4.93401 to 4.43774, saving model to /content/raccoon.h5\n",
            "Epoch 7/103\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  320 320\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            "resizing:  384 384\n",
            "resizing:  448 448\n",
            " - 28s - loss: 3.7228 - yolo_layer_1_loss: 3.0794 - yolo_layer_2_loss: 0.5026 - yolo_layer_3_loss: 0.1409\n",
            "\n",
            "Epoch 00007: loss improved from 4.43774 to 3.72282, saving model to /content/raccoon.h5\n",
            "Epoch 8/103\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            "resizing:  320 320\n",
            "resizing:  384 384\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            "resizing:  352 352\n",
            "resizing:  320 320\n",
            "resizing:  320 320\n",
            " - 27s - loss: 3.5619 - yolo_layer_1_loss: 2.8834 - yolo_layer_2_loss: 0.5024 - yolo_layer_3_loss: 0.1761\n",
            "\n",
            "Epoch 00008: loss improved from 3.72282 to 3.56190, saving model to /content/raccoon.h5\n",
            "resizing:  448 448\n",
            "Epoch 9/103\n",
            "resizing:  448 448\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  384 384\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  448 448\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            "resizing:  288 288\n",
            "resizing:  416 416\n",
            " - 28s - loss: 3.5614 - yolo_layer_1_loss: 2.7832 - yolo_layer_2_loss: 0.6980 - yolo_layer_3_loss: 0.0801\n",
            "\n",
            "Epoch 00009: loss improved from 3.56190 to 3.56136, saving model to /content/raccoon.h5\n",
            "Epoch 10/103\n",
            "resizing:  448 448\n",
            "resizing:  448 448\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  288 288\n",
            " - 29s - loss: 3.1604 - yolo_layer_1_loss: 2.6275 - yolo_layer_2_loss: 0.4173 - yolo_layer_3_loss: 0.1156\n",
            "\n",
            "Epoch 00010: loss improved from 3.56136 to 3.16043, saving model to /content/raccoon.h5\n",
            "Epoch 11/103\n",
            "resizing:  352 352\n",
            "resizing:  320 320\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  384 384\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  320 320\n",
            " - 26s - loss: 3.1261 - yolo_layer_1_loss: 2.3590 - yolo_layer_2_loss: 0.6231 - yolo_layer_3_loss: 0.1440\n",
            "\n",
            "Epoch 00011: loss improved from 3.16043 to 3.12611, saving model to /content/raccoon.h5\n",
            "Epoch 12/103\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  384 384\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  384 384\n",
            "resizing:  384 384\n",
            "resizing:  384 384\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            " - 26s - loss: 3.0589 - yolo_layer_1_loss: 2.2978 - yolo_layer_2_loss: 0.6188 - yolo_layer_3_loss: 0.1423\n",
            "\n",
            "Epoch 00012: loss improved from 3.12611 to 3.05890, saving model to /content/raccoon.h5\n",
            "Epoch 13/103\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  384 384\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            " - 27s - loss: 2.7949 - yolo_layer_1_loss: 2.0475 - yolo_layer_2_loss: 0.5857 - yolo_layer_3_loss: 0.1617\n",
            "\n",
            "Epoch 00013: loss improved from 3.05890 to 2.79488, saving model to /content/raccoon.h5\n",
            "Epoch 14/103\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            " - 27s - loss: 2.5764 - yolo_layer_1_loss: 2.0204 - yolo_layer_2_loss: 0.4386 - yolo_layer_3_loss: 0.1175\n",
            "\n",
            "Epoch 00014: loss improved from 2.79488 to 2.57644, saving model to /content/raccoon.h5\n",
            "Epoch 15/103\n",
            "resizing:  288 288\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            "resizing:  384 384\n",
            "resizing:  384 384\n",
            "resizing:  448 448\n",
            "resizing:  416 416\n",
            "resizing:  448 448\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            " - 28s - loss: 2.4672 - yolo_layer_1_loss: 2.0326 - yolo_layer_2_loss: 0.3799 - yolo_layer_3_loss: 0.0547\n",
            "\n",
            "Epoch 00015: loss improved from 2.57644 to 2.46720, saving model to /content/raccoon.h5\n",
            "Epoch 16/103\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            " - 27s - loss: 2.2751 - yolo_layer_1_loss: 1.8020 - yolo_layer_2_loss: 0.3420 - yolo_layer_3_loss: 0.1311\n",
            "\n",
            "Epoch 00016: loss improved from 2.46720 to 2.27506, saving model to /content/raccoon.h5\n",
            "Epoch 17/103\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  448 448\n",
            " - 27s - loss: 2.5768 - yolo_layer_1_loss: 1.7983 - yolo_layer_2_loss: 0.6841 - yolo_layer_3_loss: 0.0945\n",
            "\n",
            "Epoch 00017: loss did not improve from 2.27506\n",
            "Epoch 18/103\n",
            "resizing:  384 384\n",
            "resizing:  448 448\n",
            "resizing:  448 448\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            " - 29s - loss: 2.4431 - yolo_layer_1_loss: 1.7399 - yolo_layer_2_loss: 0.6524 - yolo_layer_3_loss: 0.0508\n",
            "\n",
            "Epoch 00018: loss did not improve from 2.27506\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 19/103\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            "resizing:  352 352\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  320 320\n",
            "resizing:  320 320\n",
            " - 27s - loss: 2.0928 - yolo_layer_1_loss: 1.4627 - yolo_layer_2_loss: 0.5379 - yolo_layer_3_loss: 0.0922\n",
            "\n",
            "Epoch 00019: loss improved from 2.27506 to 2.09277, saving model to /content/raccoon.h5\n",
            "Epoch 20/103\n",
            "resizing:  352 352\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  288 288\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            "resizing:  384 384\n",
            " - 27s - loss: 2.0821 - yolo_layer_1_loss: 1.2687 - yolo_layer_2_loss: 0.7032 - yolo_layer_3_loss: 0.1102\n",
            "\n",
            "Epoch 00020: loss improved from 2.09277 to 2.08206, saving model to /content/raccoon.h5\n",
            "Epoch 21/103\n",
            "resizing:  288 288\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            "resizing:  320 320\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  416 416\n",
            "resizing:  448 448\n",
            "resizing:  448 448\n",
            " - 27s - loss: 1.7652 - yolo_layer_1_loss: 1.1475 - yolo_layer_2_loss: 0.5685 - yolo_layer_3_loss: 0.0492\n",
            "\n",
            "Epoch 00021: loss improved from 2.08206 to 1.76517, saving model to /content/raccoon.h5\n",
            "Epoch 22/103\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  384 384\n",
            " - 29s - loss: 1.5181 - yolo_layer_1_loss: 1.1315 - yolo_layer_2_loss: 0.2951 - yolo_layer_3_loss: 0.0914\n",
            "\n",
            "Epoch 00022: loss improved from 1.76517 to 1.51808, saving model to /content/raccoon.h5\n",
            "Epoch 23/103\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  448 448\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            " - 27s - loss: 1.6830 - yolo_layer_1_loss: 1.0223 - yolo_layer_2_loss: 0.5524 - yolo_layer_3_loss: 0.1084\n",
            "\n",
            "Epoch 00023: loss did not improve from 1.51808\n",
            "Epoch 24/103\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            " - 29s - loss: 1.6054 - yolo_layer_1_loss: 1.0042 - yolo_layer_2_loss: 0.5029 - yolo_layer_3_loss: 0.0982\n",
            "\n",
            "Epoch 00024: loss did not improve from 1.51808\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 25/103\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            " - 27s - loss: 2.0221 - yolo_layer_1_loss: 1.3101 - yolo_layer_2_loss: 0.6199 - yolo_layer_3_loss: 0.0921\n",
            "\n",
            "Epoch 00025: loss did not improve from 1.51808\n",
            "Epoch 26/103\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  384 384\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  288 288\n",
            "resizing:  448 448\n",
            " - 26s - loss: 1.8482 - yolo_layer_1_loss: 1.1048 - yolo_layer_2_loss: 0.6169 - yolo_layer_3_loss: 0.1265\n",
            "\n",
            "Epoch 00026: loss did not improve from 1.51808\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "Epoch 27/103\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  448 448\n",
            " - 28s - loss: 1.5754 - yolo_layer_1_loss: 1.0133 - yolo_layer_2_loss: 0.4106 - yolo_layer_3_loss: 0.1515\n",
            "\n",
            "Epoch 00027: loss did not improve from 1.51808\n",
            "Epoch 28/103\n",
            "resizing:  384 384\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  416 416\n",
            "resizing:  288 288\n",
            "resizing:  448 448\n",
            "resizing:  448 448\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            " - 29s - loss: 1.4479 - yolo_layer_1_loss: 1.1402 - yolo_layer_2_loss: 0.2590 - yolo_layer_3_loss: 0.0486\n",
            "\n",
            "Epoch 00028: loss improved from 1.51808 to 1.44787, saving model to /content/raccoon.h5\n",
            "resizing:  320 320\n",
            "Epoch 29/103\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  352 352\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            " - 27s - loss: 1.6430 - yolo_layer_1_loss: 0.9694 - yolo_layer_2_loss: 0.5828 - yolo_layer_3_loss: 0.0909\n",
            "\n",
            "Epoch 00029: loss did not improve from 1.44787\n",
            "Epoch 30/103\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            "resizing:  288 288\n",
            "resizing:  448 448\n",
            "resizing:  416 416\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            "resizing:  416 416\n",
            " - 27s - loss: 1.5937 - yolo_layer_1_loss: 0.9599 - yolo_layer_2_loss: 0.6276 - yolo_layer_3_loss: 0.0062\n",
            "\n",
            "Epoch 00030: loss did not improve from 1.44787\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
            "Epoch 31/103\n",
            "resizing:  288 288\n",
            "resizing:  320 320\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  448 448\n",
            "resizing:  448 448\n",
            " - 28s - loss: 1.4845 - yolo_layer_1_loss: 0.9856 - yolo_layer_2_loss: 0.3902 - yolo_layer_3_loss: 0.1087\n",
            "\n",
            "Epoch 00031: loss did not improve from 1.44787\n",
            "Epoch 32/103\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  320 320\n",
            "resizing:  320 320\n",
            "resizing:  288 288\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  448 448\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            " - 25s - loss: 2.1874 - yolo_layer_1_loss: 1.1771 - yolo_layer_2_loss: 0.8364 - yolo_layer_3_loss: 0.1739\n",
            "\n",
            "Epoch 00032: loss did not improve from 1.44787\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
            "Epoch 33/103\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            "resizing:  448 448\n",
            "resizing:  416 416\n",
            "resizing:  448 448\n",
            "resizing:  384 384\n",
            "resizing:  288 288\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  288 288\n",
            " - 27s - loss: 1.8761 - yolo_layer_1_loss: 1.0787 - yolo_layer_2_loss: 0.6865 - yolo_layer_3_loss: 0.1109\n",
            "\n",
            "Epoch 00033: loss did not improve from 1.44787\n",
            "Epoch 34/103\n",
            "resizing:  288 288\n",
            "resizing:  448 448\n",
            "resizing:  320 320\n",
            "resizing:  448 448\n",
            "resizing:  384 384\n",
            "resizing:  320 320\n",
            "resizing:  352 352\n",
            "resizing:  352 352\n",
            "resizing:  416 416\n",
            "resizing:  384 384\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            " - 27s - loss: 1.5374 - yolo_layer_1_loss: 0.9853 - yolo_layer_2_loss: 0.4617 - yolo_layer_3_loss: 0.0905\n",
            "\n",
            "Epoch 00034: loss did not improve from 1.44787\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
            "Epoch 35/103\n",
            "resizing:  288 288\n",
            "resizing:  416 416\n",
            "resizing:  416 416\n",
            "resizing:  352 352\n",
            "resizing:  384 384\n",
            "resizing:  416 416\n",
            "resizing:  320 320\n",
            "resizing:  384 384\n",
            "resizing:  288 288\n",
            "resizing:  448 448\n",
            "resizing:  352 352\n",
            "resizing:  320 320\n",
            "resizing:  384 384\n",
            " - 26s - loss: 1.9480 - yolo_layer_1_loss: 0.9094 - yolo_layer_2_loss: 0.9037 - yolo_layer_3_loss: 0.1348\n",
            "\n",
            "Epoch 00035: loss did not improve from 1.44787\n",
            "Epoch 00035: early stopping\n",
            "raccoon: 0.9762\n",
            "mAP: 0.9762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "185rzO2_B4AK",
        "colab_type": "text"
      },
      "source": [
        "Sau khi quá trình huấn luyện kết thúc, hệ thống sẽ lưu mô hình raccoon.h5 trong thư mục của máy ảo colab. Ta có thể sửa lại mã nguồn của thư viện để các file mô hình và file trung gian đặt trong thư mục của thư viện cho gọn gàng.\n",
        "\n",
        "Sau đó, ta sẽ tiến hành thử nghiệm mô hình đã huấn luyện trên ảnh mẫu lấy từ mạng internet hoặc thư mục ảnh validation/train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNy0y0fstq-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af8cd224-14ab-4d6f-fa46-1beebac491a7"
      },
      "source": [
        "!python $lab_path/predict.py -c $lab_path/zoo/config_raccoon.json -i '/content/Bernese-Mountain-Dog-On-White-01.jpg'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2020-07-15 12:57:47.701296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-15 12:57:47.722474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 12:57:47.723343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-15 12:57:47.723909: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-15 12:57:47.730666: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-15 12:57:47.734272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-15 12:57:47.735206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-15 12:57:47.749345: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-15 12:57:47.751760: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-15 12:57:47.774321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-15 12:57:47.774480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 12:57:47.775438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 12:57:47.776488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-15 12:57:47.777025: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-07-15 12:57:47.782669: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-07-15 12:57:47.783000: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2eb8d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-15 12:57:47.783028: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-07-15 12:57:47.883151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 12:57:47.884263: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2eb8f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-15 12:57:47.884314: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-07-15 12:57:47.884546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 12:57:47.885648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-15 12:57:47.885759: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-15 12:57:47.885801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-15 12:57:47.885858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-15 12:57:47.885900: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-15 12:57:47.885938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-15 12:57:47.885979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-15 12:57:47.886021: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-15 12:57:47.886138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 12:57:47.887014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 12:57:47.887797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-15 12:57:47.887881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-15 12:57:47.889379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-15 12:57:47.889412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-15 12:57:47.889428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-15 12:57:47.889597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 12:57:47.890531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 12:57:47.891479: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-07-15 12:57:47.891560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n",
            "/content/Bernese-Mountain-Dog-On-White-01.jpg\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "2020-07-15 12:57:57.858824: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-15 12:57:58.981756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcHPECkzCZb7",
        "colab_type": "text"
      },
      "source": [
        "Như vậy, trong phần bài tập này chúng ta đã làm quen với thư viện keras-yolo3. Trong phần đồ án giữa kỳ, ta sẽ tiến hành trên dữ liệu video giao thông được thu tại TP. Hồ Chí Minh. Ví dụ, ảnh sau được cắt tại góc đường Nam Kỳ Khởi Nghĩa - Võ Thị Sáu.\n",
        "\n",
        "![alt text](https://i.imgur.com/NQBeNpG.jpg)\n",
        "\n",
        "Mục tiêu của đồ án này là sử dụng thuật toán YOLOv3 để tiến hành ước lượng lưu lượng giao thông theo các hướng đi.\n",
        "\n",
        "Đầu tiên, ta sẽ thử sử dụng pretrained model lên dữ liệu video thực tế.\n",
        "\n",
        "Sau đó tiến hành xây dựng bộ dữ liệu gán nhãn cho ngữ cảnh camera giao thông.\n",
        "\n",
        "Huấn luyện lại mô hình với dữ liệu gán nhãn mới.\n",
        "\n",
        "Phát hiện và đếm các đối tượng xe máy, xe hơi trong video giao thông.\n",
        "\n"
      ]
    }
  ]
}